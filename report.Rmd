---
title: 'Neutralise: Summary Report'
author: "Leyla Kodalci"
date: "2023-02-07"
output:
  html_document: default
  pdf_document: 
    extra_dependencies: ["float"]
  word_document: default
---

In this report, we will summarize the results of methods that have been neutralized and show the results that give more insights to the method and simulation scenarios. In section 1, the methods included in this framework will be summarized. In section 2, we will show the type I error rate control of all methods per data generation method. In section 3, the power-power plots of a few selected methods will be discussed, as well as the power-power plots that compare a method to the best results over the different scenario's.

All the results shown in this report can be reproduced using the data in NeutraliseFiles or in the shiny app. This report is the results of choices made by the author, which can be viewed as not neutral. However, we believe that this report doesn't jeopardize the Neutralise initiative as all the results in this report can be reproduced. These results, as well as the results that are not included in this report, are publicly available and can be consulted. This report has been produced with Neutralise (v0.1.0). 

## 1. Methods

```{r setup,echo=F,include=F}
# Load required packages
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\lucp9827\\Desktop\\Neutralise_end_Dash - report")
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
knitr::opts_chunk$set(fig.pos = 'H')
library(Neutralise)
library(ggplot2)
library(knitr)
library(dplyr)
library(kableExtra)
```

\renewcommand{\arraystretch}{2}
```{r,echo=F}
methods= sum_methods()

kable(methods,booktabs=T,caption = "Table 1: Summary of included methods")%>%
  kable_styling(latex_options=c("HOLD_position"))%>%
  column_spec(1,width_min="1em")%>%
  column_spec(2,width_min="1em")%>%
  column_spec(3,width_min='5em')%>%
  column_spec(4,width_min='5em')%>%
  landscape()

```



## 2. Type I error rate control

Figure 1 shows the emprical type I error rates of all included methods per data generation method. All tests were performed at the 5% level of significance (red dotted line), and the error rates were computed based on 10000 simulation runs. Points above (below) the lower and upper horizontal reference lines (black dotted line) correspond to liberal (conservative) tests. The liberal tests are the test that have a type I error rate (upper confidence interval of the type I error rate) above the the upper reference line. These liberal tests will be filtered out of the results, as comparing these methods to methods that control the type I error would not be fair or sensible.

The percentile modified Wilcoxon-Mann-Whitney test (Gastwirth), has a type I error rate that is too liberal in all scenarios and will be filtered out. The Welch two sample t-test and the Yuen's test do not control the type I error rate control for scenarios of the exponential distribution, and the g-h distribution. These are scenarios with unequal sample sizes. The two sample student-t test is too liberal for scenarios from the Cauchy distribution with unequal sample sizes between the two groups. In contrast, the asymptotic Kolmogorov-Smirnov test and the Mood's median test have a type I error rate control that is very conservative.

```{r ,echo=F,warning=F, fig.height=10,fig.width=10, fig.pos='H',fig.cap="boxplots of the empirical type I error rates. All tests were performed at 5% significance level (red dotted line), and the error rates were computed based on 10000 simulation runs." }

path="C:\\Users\\lucp9827\\Desktop\\Neutralise_end_Dash - report"
Boxplot_TypeI(path,panel="distribution")$graph
```

## 3. Power-power curve: Best method

In the figures below (Figure:2-5), the power-power curves are shown between the specified method versus the 'best' performing method in that specific scenario setting (distribution). These plots are given for sample size 20 (left column) and sample size 200 (right column). All 14 methods are included, we excluded Gastwirth as the method had a type I error rate that was far too liberal for most scenarios. In general, the results with sample size 20 are more scattered, while the results of sample size 200 are more centered around the diagonal and more specifically the top right of the diagonal (highest power results), which is expected as the power increases with sample size. The tests that had a very conservative type I error rate control (KS, Mood), also show power-power curves that reflect the lack of power in comparison to the best performing methods. This lack in power is also noticeable for the results for the Cauchy and g-h distributions of the two sample Student-t test and the Welch t-test. Remarkably, for some scenarios of the normal distributions with unequal variances, the Welch t-test has much lower power than the best competitor, the best competitor is the two sample smooth test with fixed order 4 and Legendre polynomials. For the WMW test, the power-power plot shows that the test has at least similar results in comparison to the best method for the logistic distribution with sample size 200 (as expected), but for the small sample sizes slightly better tests exist. The plots of Anderson-Darling(AD) have more of the observations around the diagonal for both sample sizes in comparison to all other methods. Hence, the AD test has often the largest power, and when it does not, its power is not much smaller than the power of the best competitor (i.e. the points are close to the diagonal). The worst performing test is the two sample smooth test with fixed order 6 and Legendre Polynomials. Based on these results we selected AD, KS, the Welsh test, Student-t test, WmW test and two sample smooth test with fixed order 4 and Legendre polynomials. Hence, the plots are better evaluated in some more detail in the next section.

```{r,echo=F,warning=F, fig.show="hold",out.width="50%",fig.cap="Power-Power curve, comparison to the best performing method in that specific scenario setting. Left column is specified for a total sample size 20 and the right column for a total sample size 200.  "}

Best_method_plot(path,"AD",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"AD",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"KS",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"KS",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"CVM",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"CVM",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"TTest_VarEqual",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"TTest_VarEqual",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph

```

```{r,echo=F,warning=F, fig.show="hold",out.width="50%",fig.cap="Power-Power curve, comparison to the best performing method in that specific scenario setting. Left column is specified for a total sample size 20 and the right column for a total sample size 200.  "}

Best_method_plot(path,"TTest_VarUnequal",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"TTest_VarUnequal",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"Yuen",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"Yuen",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"BM",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"BM",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"VW",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"VW",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph


```

```{r,echo=F,warning=F, fig.show="hold",out.width="50%",fig.cap="Power-Power curve, comparison to the best performing method in that specific scenario setting. Left column is specified for a total sample size 20 and the right column for a total sample size 200.  "}

Best_method_plot(path,"Mood",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"Mood",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"HFR",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"HFR",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"CVM",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"CVM",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"WMW_Asymp",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"WMW_Asymp",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
```

```{r,echo=F,warning=F, fig.show="hold",out.width="50%",fig.cap="Power-Power curve, comparison to the best performing method in that specific scenario setting. Left column is specified for a total sample size 20 and the right column for a total sample size 200.  "}

Best_method_plot(path,"SmoothFixed_4_asymp",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"SmoothFixed_4_asymp",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"SmoothFixed_6_asymp",n=20,alpha=0.05,name_methods=NULL,N=10000)$graph
Best_method_plot(path,"SmoothFixed_6_asymp",n=200,alpha=0.05,name_methods=NULL,N=10000)$graph
```



## 4. Power-Power curve

The power-power plots are based on 10000 simulation runs and 5% significance level. The scenarios where the type I error was too liberal are filtered out. The first comparison (Figure 3, top left), the Anderson-Darling test (AD) versus the Kolmogrov Smirnov test (KS), shows that AD has a higher power in most scenarios. For some scenario's in the Cauchy distribution and Normal distribution with unequal variances, KS has a higher power. These scenarios are characterized with unequal sample sizes. Moreover, the asymmetry of the plot suggests that when the AD outperforms the KS test, it is by a larger margin than it is the other way around. The power-power plot of the two sample student t-test and the Welch test (Figure 6, top right), show the results of most scenarios are close to the diagonal which means that they have similar results in those scenarios. However for the scenarios from the Normal distribution with unequal variances and unequal sample sizes, the Welch test outperforms the two sample student-t test. The third comparison (Figure 6, down left), compares the Welch t-test to the Wilcoxon-Mann-Whitney test (WMW). In this comparison it's clear that WMW outperforms the Welch t-test for scenarios from the Cauchy and Exponential distribution. The plot also shows that many points are close to the diagonal (particularly for the symmetric distributions), indicating that for these distributions the powers of the two tests are close to one another. However, there are still many other points far off the diagonal, towards both sides. This shows that for some scenarios (skew and/or heavy tailed distributions) the powers of the WMW test and the Welch t-test may be very different. Sometimes the WMW wins, other times the Welch t-test wins. The last plot (Figure 6, down right) compares WMW with Two sample smooth test with fixed order 4 and Legendre polynomials. WMW outperforms the smooth test in the logistic distribution, and has a higher power in the scenarios that come from the more symmetric distributions. In contrast, the smooth test has a higher power in the more skewed and/or heavy tailed distributions, which is what we would expect from the smooth test.

```{r,echo=F,warning=F, figures-side, fig.show="hold",out.width="50%",fig.cap="Power-Power plots for comparing two methods. Top left: Anderson-Darling versus Kolmogrov Smirnov test. Top right: Welch versus the two sample student-t test. Down left: Welch two sample test versus the Wilcoxon-Mann-Whitney test. Down Right: Two sample smooth test with fixed order 4 and Legendre polynomials versus the Wilcoxon-Mann-Whitney test."}
pp1 = Power_QQ(path,"AD","KS",alpha=0.05,group=TRUE,N=10000)
pp1$graph
pp2 = Power_QQ(path,"TTest_VarEqual","TTest_VarUnequal",alpha=0.05,group=TRUE,N=10000)
pp2$graph
pp3 = Power_QQ(path,"WMW_Asymp","TTest_VarUnequal",alpha=0.05,group=TRUE,N=10000)
pp3$graph
pp4 = Power_QQ(path,"WMW_Asymp","SmoothFixed_4_asymp",alpha=0.05,group=TRUE,N=10000)
pp4$graph
```

## 5. Conclusion

In terms of Type I error rate control the results has shown that the Welch test and Yuen test, which is a derivative of the Welch test but with trimmed means, do not perform well for skewed and heavy tailed distributions in combination with unequal sample sizes. Moods test and KS, have a conservative type I error rate control, especially for small sample sizes. 
The methods that have a conservative type I error rate have shown that they are also lacking in terms of power. AD has performed well in most scenarios. The WMW test performed well in scenarios with symmetrical distributions (with equal sample sizes), but less in scenarios with opposite skewed distributions and heavy tailed distributions.  
In general, the methods perform well for the distributions and scenarios they are developed for. The methods are distinguised from each other in scenarios that have small sample size and/or unequal balanced design, in combination with skewed and heavy tailed distributions. Here, the more robust methods such as AD, CVM perform better. 


